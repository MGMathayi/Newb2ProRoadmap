{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = []\n",
    "labels = []\n",
    "for i in os.listdir(r\"D:\\Datasets\\Kaggle\\afhq\"):\n",
    "    for label in os.listdir(rf\"D:\\Datasets\\Kaggle\\afhq\\{i}\"):\n",
    "        for image in os.listdir(rf\"D:\\Datasets\\Kaggle\\afhq\\{i}\\{label}\"):\n",
    "            image_path.append(rf\"D:\\Datasets\\Kaggle\\afhq\\{i}\\{label}\\{image}\")\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(zip(image_path, labels), columns = [\"image_path\", \"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11291, 2)\n",
      "(2420, 2)\n",
      "(2419, 2)\n"
     ]
    }
   ],
   "source": [
    "train = data_df.sample(frac = 0.7)\n",
    "test = data_df.drop(train.index)\n",
    "val = test.sample(frac=0.5)\n",
    "test = test.drop(val.index)\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_df[\"labels\"])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform = None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.labels = torch.tensor(label_encoder.transform(dataframe['labels'])).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open[image_path].convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image).to(device)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjecrtEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
